{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import datetime\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from weather_data_class_v1 import WeatherData\n",
    "\n",
    "class TrainingClass(WeatherData):\n",
    "    def __init__(self, ds: xr.Dataset, window_size: int, steps: int, use_forcings: bool = False, intervals: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the TorchWeatherModel.\n",
    "\n",
    "        Args:\n",
    "            ds (xr.Dataset): The xarray dataset containing weather data.\n",
    "            window_size (int): The size of the window for input data. Default is 24.\n",
    "            steps (int): Number of future steps to predict. Default is 3.\n",
    "            use_forcings (bool): Whether to use forcings such as time-based inputs (e.g., hour, month). Default is False.\n",
    "            intervals (int): Interval for processing the dataset. Default is 1.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(dataset=ds, \n",
    "                         window_size=window_size, \n",
    "                         steps=steps, \n",
    "                         auto=True, \n",
    "                         use_forcings=use_forcings, \n",
    "                         intervals=intervals)\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print('Class setup done...')\n",
    "\n",
    "    def train_multi(self, epochs: int = 10, save_path: str = None, patience: int = 5, lr_: float = 0.0001, batch_size_: int = 128, train_steps: int = 3, load_weights: str = None) -> None:\n",
    "        \"\"\"\n",
    "        Train the model with a multi-step autoregressive approach.\n",
    "\n",
    "        Args:\n",
    "            epochs (int): Number of training epochs. Default is 10.\n",
    "            save_path (str): Path to save the best model. Default is timestamp-based.\n",
    "            patience (int): Number of epochs to wait for improvement before stopping. Default is 5.\n",
    "            lr_ (float): Learning rate for the optimizer. Default is 0.0001.\n",
    "            batch_size_ (int): Batch size for DataLoader. Default is 128.\n",
    "            train_steps (int): Number of autoregressive steps during training. Default is 3.\n",
    "            load_weights (str): Path to pre-trained model weights. Default is None.\n",
    "        \"\"\"\n",
    "        \n",
    "        if save_path is None:\n",
    "            save_path = f'{datetime.now().month}_{datetime.now().day}_{datetime.now().hour}_{datetime.now().minute}.pth'\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr_)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "        print(f'Training on {self.device}')\n",
    "\n",
    "        if load_weights is not None:\n",
    "            self.load_model(load_weights)\n",
    "        else:\n",
    "            self.model.apply(self.init_weights)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "\n",
    "        # TODO: Implement the training and validation steps in the model itself to avoid code duplication\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            self.data_split = 'train'\n",
    "            for X_batch, F_batch, y_batch in DataLoader(self, batch_size=batch_size_, shuffle=True):\n",
    "                X_batch = X_batch.to(self.device)\n",
    "                F_batch = F_batch.to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                cumulative_loss = 0.0\n",
    "                current_input = X_batch.clone()  \n",
    "                current_F = F_batch.clone()\n",
    "\n",
    "                for step in range(train_steps): \n",
    "                    \n",
    "                    if self.use_forcings:\n",
    "                        outputs = self.model(current_input, current_F)\n",
    "                    else:\n",
    "                        outputs = self.model(current_input)\n",
    "                    \n",
    "                    loss = criterion(outputs, y_batch[:, step].reshape(-1, 1, self.dataset.latitude.size, self.dataset.longitude.size))\n",
    "                    cumulative_loss += loss  \n",
    "                    \n",
    "                    current_input = torch.cat((current_input[:, 1:], outputs), dim=1).to(self.device)\n",
    "\n",
    "                    hour = current_F[:, 0]\n",
    "                    month = current_F[:, 1]\n",
    "                    \n",
    "                    hour = (hour + 1) % 24\n",
    "\n",
    "                    current_F = torch.stack((hour, month), dim=1).float().to(self.device)\n",
    "\n",
    "                cumulative_loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += cumulative_loss.item() * X_batch.size(0)\n",
    "\n",
    "            avg_loss = epoch_loss / len(self.X_train)\n",
    "\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "            print(f'Training: Epoch {epoch+1}/{epochs}, Loss: {avg_loss}, Best Loss: {best_loss}, LR: {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "            self.data_split = 'val'\n",
    "            self.model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "            with torch.no_grad():  # Disable gradient computation for validation\n",
    "                for X_batch, F_batch, y_batch in DataLoader(self, batch_size=batch_size_, shuffle=False):\n",
    "                    X_batch = X_batch.to(self.device)\n",
    "                    F_batch = F_batch.to(self.device)\n",
    "                    y_batch = y_batch.to(self.device)\n",
    "                    \n",
    "                    cumulative_loss = 0.0\n",
    "                    current_input = X_batch.clone()  \n",
    "                    current_F = F_batch.clone()\n",
    "\n",
    "                    for step in range(train_steps): \n",
    "                        \n",
    "                        if self.use_forcings:\n",
    "                            outputs = self.model(current_input, current_F)\n",
    "                        else:\n",
    "                            outputs = self.model(current_input)\n",
    "                        \n",
    "                        loss = criterion(outputs, y_batch[:, step].reshape(-1, 1, self.dataset.latitude.size, self.dataset.longitude.size))\n",
    "                        cumulative_loss += loss  \n",
    "                        \n",
    "                        current_input = torch.cat((current_input[:, 1:], outputs), dim=1).to(self.device)\n",
    "\n",
    "                        hour = current_F[:, 0]\n",
    "                        month = current_F[:, 1]\n",
    "                        \n",
    "                        hour = (hour + 1) % 24\n",
    "\n",
    "                        current_F = torch.stack((hour, month), dim=1).float().to(self.device)\n",
    "\n",
    "                    epoch_loss += cumulative_loss.item() * X_batch.size(0)\n",
    "\n",
    "            print(f'Validation: Epoch {epoch+1}/{epochs}, Loss: {avg_loss}, Best Loss: {best_loss}, LR: {optimizer.param_groups[0][\"lr\"]}')\n",
    "            \n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.model.state_dict(), save_path)\n",
    "                print(f'Saved best model to {save_path}')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print('Early stopping triggered')\n",
    "                break\n",
    "\n",
    "    def init_weights(self, m: nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Initialize weights for the model.\n",
    "\n",
    "        Args:\n",
    "            m (nn.Module): Module whose weights will be initialized.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight) \n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def assign_model(self, model: nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Assign a model to the class instance.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): A PyTorch model to assign for training and prediction.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Load a model from a file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to load the model from.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.load_state_dict(torch.load(file_path, map_location=self.device, weights_only=True))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, X: torch.Tensor, F: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predict output based on input data.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input data for prediction.\n",
    "            F (torch.Tensor): Forcings data, such as hour and month (if used).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Model predictions.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            X = torch.tensor(X).float()\n",
    "            F = torch.tensor(F).float()\n",
    "            if self.use_forcings:\n",
    "                return self.model(X, F).numpy()\n",
    "            else:\n",
    "                return self.model(X).numpy()\n",
    "\n",
    "    def autoregressive_predict(self, X: torch.Tensor, F: torch.Tensor, rollout_steps: int, unnormalize: bool = True, verbose: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Perform autoregressive predictions for multiple time steps.\n",
    "\n",
    "        Args:\n",
    "            X (torch.Tensor): Input data for prediction.\n",
    "            F (torch.Tensor): Forcings data, such as hour and month.\n",
    "            rollout_steps (int): Number of future steps to predict.\n",
    "            unnormalize (bool): Whether to unnormalize the predictions. Default is True.\n",
    "            verbose (bool): Whether to print intermediate shapes for debugging. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Predictions for each time step.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # X = torch.tensor(X).float()\n",
    "            F = torch.tensor(F).float()\n",
    "            \n",
    "            predictions = []\n",
    "\n",
    "            current_input = X#.to(self.device)\n",
    "            current_F = F#.to(self.device)\n",
    "            \n",
    "            for step in range(rollout_steps):\n",
    "                \n",
    "                if self.use_forcings:\n",
    "                    next_pred = self.model(current_input, current_F).cpu().numpy()\n",
    "                else:\n",
    "                    try:\n",
    "                        next_pred = self.model(current_input).cpu().numpy()\n",
    "                    except:\n",
    "                        next_pred = self.model(current_input).numpy()\n",
    "                \n",
    "                predictions.append(next_pred)\n",
    "                \n",
    "                next_pred_tensor = torch.tensor(next_pred).float()#.to(self.device) \n",
    "\n",
    "                if verbose:\n",
    "                    print(current_input.shape, next_pred_tensor.shape)\n",
    "\n",
    "                current_input = torch.cat((current_input[:, 1:], next_pred_tensor), dim=1)#.to(self.device)\n",
    "\n",
    "                hour = current_F[0, 0].item()  # Extract the hour\n",
    "                month = current_F[0, 1].item()  # Extract the month\n",
    "                \n",
    "                hour += 1\n",
    "                if hour == 24:\n",
    "                    hour = 0\n",
    "                \n",
    "                current_F = torch.tensor([[hour, month]]).float()#.to(self.device)\n",
    "\n",
    "            predictions = np.array(predictions).reshape(rollout_steps, self.dataset.sizes['latitude'], self.dataset.sizes['longitude'])\n",
    "\n",
    "            # Unnromalize the predictions\n",
    "            if unnormalize:\n",
    "                predictions = predictions * self.std_value + self.mean_value\n",
    "            \n",
    "            return predictions\n",
    "        \n",
    "    def plot_pred_target(self, seed: int = 0, frame_rate: int = 16, levels: int = 10) -> HTML:\n",
    "        \"\"\"\n",
    "        Plot the predictions and targets with animations.\n",
    "\n",
    "        Args:\n",
    "            seed (int): Seed to select the test data for plotting. Default is 0.\n",
    "            frame_rate (int): Frame rate for animation. Default is 16.\n",
    "            levels (int): Number of contour levels for plots. Default is 10.\n",
    "\n",
    "        Returns:\n",
    "            HTML: An HTML object containing the animation of predictions and targets.\n",
    "        \"\"\"\n",
    "\n",
    "        bounds = [self.dataset.longitude.min().item(), self.dataset.longitude.max().item(), self.dataset.latitude.min().item(), self.dataset.latitude.max().item()]\n",
    "        targets = self.X_test[seed + self.window_size:seed + self.window_size + self.steps]\n",
    "        time_values = self.T_test[seed + self.window_size:seed + self.window_size + self.steps]\n",
    "\n",
    "        time_values = pd.to_datetime(time_values)\n",
    "\n",
    "        predictions = self.autoregressive_predict(self.X_test_t[seed:seed + self.window_size].unsqueeze(0), self.F_test_t[seed + self.window_size].unsqueeze(0), self.steps)\n",
    "\n",
    "        fig, axs = plt.subplots(2, 3, figsize=(21, 7), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "        vmin = min(predictions.min().item(), targets.min().item())\n",
    "        vmax = max(predictions.max().item(), targets.max().item())\n",
    "\n",
    "        fig.subplots_adjust(left=0.05, right=0.95, bottom=0.1, top=0.9, wspace=0.2)\n",
    "\n",
    "        for ax in axs.flatten()[:-1]:\n",
    "            ax.set_extent(bounds, crs=ccrs.PlateCarree())\n",
    "            ax.coastlines()\n",
    "\n",
    "        ax_last = fig.add_subplot(2, 3, 6)\n",
    "\n",
    "        pred = axs[0, 0].contourf(self.dataset.longitude, self.dataset.latitude, predictions[0], levels=levels, vmin=vmin, vmax = vmax, transform=ccrs.PlateCarree())\n",
    "        tar = axs[0, 1].contourf(self.dataset.longitude, self.dataset.latitude, targets[0], levels=levels, vmin=vmin, vmax = vmax, transform=ccrs.PlateCarree())\n",
    "\n",
    "        error = (predictions[0] - targets[0,0].squeeze()) \n",
    "\n",
    "        err = axs[0, 2].contourf(self.dataset.longitude, self.dataset.latitude, error.squeeze(), levels=levels, transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "\n",
    "        perc_error = error / targets[0,0].squeeze() * 100\n",
    "        perc_error = np.clip(perc_error, -100, 100)\n",
    "        rmse = np.sqrt(error**2)\n",
    "\n",
    "        perr = axs[1, 0].contourf(self.dataset.longitude, self.dataset.latitude, perc_error, levels=levels, transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "        rms = axs[1, 1].contourf(self.dataset.longitude, self.dataset.latitude, rmse, levels=levels, transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "        ax_last.scatter(targets[0].flatten(), predictions[0].flatten(), c=error, cmap='coolwarm')\n",
    "\n",
    "        fig.colorbar(pred, ax=axs[0, 0], orientation='vertical', label='Wind Speed (m/s)')\n",
    "        fig.colorbar(tar, ax=axs[0, 1], orientation='vertical', label='Wind Speed (m/s)')\n",
    "        fig.colorbar(err, ax=axs[0, 2], orientation='vertical', label='Percentage Error (%)')\n",
    "        fig.colorbar(perr, ax=axs[1, 0], orientation='vertical', label='Percentage Error (%)')\n",
    "        fig.colorbar(rms, ax=axs[1, 1], orientation='vertical', label='Root Mean Squared Error (m/s)')\n",
    "\n",
    "        ax_last.set_xlabel(\"Observed Wind Speed (m/s)\")\n",
    "        ax_last.set_ylabel(\"Forecasted Wind Speed (m/s)\")\n",
    "\n",
    "        def animate(i):\n",
    "            for ax in axs.flatten()[:-1]:\n",
    "                ax.clear()\n",
    "                ax.coastlines()\n",
    "            \n",
    "            ax_last.clear()\n",
    "            ax_last.set_xlabel(\"Observed Wind Speed (m/s)\")\n",
    "            ax_last.set_ylabel(\"Forecasted Wind Speed (m/s)\")\n",
    "\n",
    "            axs[0, 0].contourf(self.dataset.longitude, self.dataset.latitude, predictions[i], levels=levels, vmin=vmin, vmax = vmax)\n",
    "            axs[0, 1].contourf(self.dataset.longitude, self.dataset.latitude, targets[i], levels=levels, vmin=vmin, vmax = vmax)\n",
    "            \n",
    "            error =  (predictions[i] - targets[i].squeeze())\n",
    "            axs[0, 2].contourf(self.dataset.longitude, self.dataset.latitude, error, levels=levels, transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "            \n",
    "            perc_error = error / targets[i % self.steps].squeeze() * 100\n",
    "            perc_error = np.clip(perc_error, -100, 100)\n",
    "            rmse = np.sqrt(error**2)\n",
    "\n",
    "            axs[1, 0].contourf(self.dataset.longitude, self.dataset.latitude, perc_error, levels=levels, transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "            axs[1, 1].contourf(self.dataset.longitude, self.dataset.latitude, rmse, levels=levels, transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "            ax_last.scatter(targets[i].flatten(), predictions[i].flatten(), c=error, cmap='coolwarm')\n",
    "\n",
    "            axs[0, 0].set_title(f'Prediction {i} - {time_values[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')  \n",
    "            axs[0, 1].set_title(f'Target - {time_values[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "            axs[0, 2].set_title(f'Error - {time_values[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "            axs[1, 0].set_title(f'Percentage Error - {time_values[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "            axs[1, 1].set_title(f'Root Mean Squared Error - {time_values[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "            ax_last.set_title(f'Error Scatter Plot - {time_values[i].strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "        frames = predictions.shape[0]\n",
    "\n",
    "        interval = 1000 / frame_rate\n",
    "\n",
    "        ani = FuncAnimation(fig, animate, frames=frames, interval=interval)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "        return HTML(ani.to_jshtml())\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, forcing_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size + forcing_size, 128)  \n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, output_size)  \n",
    "\n",
    "    def forward(self, X, F):\n",
    "        batch_size = X.size(0)\n",
    "        X = X.view(batch_size, -1) \n",
    "\n",
    "        inputs = torch.cat((X, F), dim=1) \n",
    "\n",
    "        x = torch.relu(self.fc1(inputs))  \n",
    "        x = torch.relu(self.fc2(x))  \n",
    "        x = self.fc3(x) \n",
    "\n",
    "        return x.view(-1, 1, 16, 32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "class PrepData:\n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the PrepData class.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the .nc file containing weather data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ds = xr.open_dataset(file_path)\n",
    "        self.ds.load()\n",
    "\n",
    "        self.ds['wspd'] = np.sqrt(self.ds.u ** 2 + self.ds.v ** 2)\n",
    "\n",
    "        self.dataset = self.ds.sortby('latitude')\n",
    "\n",
    "    def fit_shape(self, lat_slice=slice(1, 33), lon_slice=slice(3, 67)) -> None:\n",
    "        \"\"\"\n",
    "        Slice the dataset to the specified latitude and longitude ranges.\n",
    "\n",
    "        Args:\n",
    "            lat_slice (slice): Slice object specifying the range of latitude indices to select. \n",
    "                            Default is slice(1, 33).\n",
    "            lon_slice (slice): Slice object specifying the range of longitude indices to select. \n",
    "                            Default is slice(3, 67).\n",
    "\n",
    "        This method uses `isel` to index along the latitude and longitude dimensions and \n",
    "        subsets the dataset based on the specified slice ranges.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ds = self.ds.isel(latitude=lat_slice, longitude=lon_slice)\n",
    "\n",
    "    def coarsen(self, factor: int) -> None:\n",
    "        \"\"\"\n",
    "        Coarsen the dataset by a factor.\n",
    "\n",
    "        Args:\n",
    "            factor (int): Factor to coarsen the dataset by.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ds = self.ds.coarsen(latitude=factor, longitude=factor, boundary='trim').mean()\n",
    "\n",
    "    def plot_wind_speed(self, time_index: int = 0) -> None:\n",
    "        \"\"\"\n",
    "        Plot the wind speed at a specific time index.\n",
    "\n",
    "        Args:\n",
    "            time_index (int): Time index to plot. Default is 0.\n",
    "        \"\"\"\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "        ax.coastlines()\n",
    "\n",
    "        self.ds['wspd'].isel(time=time_index).plot(transform=ccrs.PlateCarree())\n",
    "\n",
    "    def save_wind_speed(self, save_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Save the wind speed as a .npy file.\n",
    "\n",
    "        Args:\n",
    "            save_path (str): Path to save the .npy file.\n",
    "        \"\"\"\n",
    "\n",
    "        np_wspd = self.ds['wspd'].values\n",
    "        np_forcings = np.stack((self.ds.time.dt.hour.values, self.ds.time.dt.month.values), axis=-1)\n",
    "        np_time_values = self.ds.time.values\n",
    "\n",
    "        save_path_wspd = save_path + '_wspd_850_SA.npy'\n",
    "        save_path_forcings = save_path + '_forcings_850_SA.npy'\n",
    "        save_path_time = save_path + '_time_850_SA.npy'\n",
    "\n",
    "        # np.save(save_path_wspd, np_wspd)\n",
    "        # np.save(save_path_forcings, np_forcings)\n",
    "        np.save(save_path_time, np_time_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\23603526\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xarray\\backends\\plugins.py:80: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "Cannot find the ecCodes library\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "prep_data = PrepData('data_850/2018_850_SA.nc')\n",
    "prep_data.coarsen(2)\n",
    "prep_data.fit_shape()\n",
    "# prep_data.save_wind_speed('2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16,), (32,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat = prep_data.ds.latitude.values\n",
    "lon = prep_data.ds.longitude.values\n",
    "\n",
    "lat.shape, lon.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
